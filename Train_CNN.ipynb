{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDeepHub/ParkingDetector/blob/main/Train_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETLPsByiaw6V",
        "outputId": "aba50949-b70b-4558-f042-8d6ee1105338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents extracted to /content/parking_dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to your zip file\n",
        "zip_path = '/content/clf-data.zip'  # Change this to the path of your zip file\n",
        "\n",
        "# Specify the directory to extract the contents into\n",
        "extract_to = '/content/parking_dataset'  # Change this to your desired output directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(extract_to):\n",
        "    os.makedirs(extract_to)\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Contents extracted to {extract_to}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcqRlj-Vev0i"
      },
      "source": [
        "Before defining how we will be importing the images into TensorFlow, we´ll make a quick analysis of the images dimensions. They don´t have a standard size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCEMRIFQeu8F",
        "outputId": "ebaf1672-0ed3-46eb-f8c1-e9fa1b975e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 'empty':\n",
            "  5 Largest: [TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65])]\n",
            "  5 Smallest: [TensorShape([26, 62]), TensorShape([26, 62]), TensorShape([26, 62]), TensorShape([26, 62]), TensorShape([26, 62])]\n",
            "  Average Size: (28.945484400656813, 67.66863711001642)\n",
            "Class 'not_empty':\n",
            "  5 Largest: [TensorShape([33, 69]), TensorShape([33, 69]), TensorShape([33, 69]), TensorShape([33, 69]), TensorShape([33, 69])]\n",
            "  5 Smallest: [TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61])]\n",
            "  Average Size: (28.770443349753695, 68.21182266009852)\n",
            "Overall:\n",
            "  5 Largest: [TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65]), TensorShape([36, 65])]\n",
            "  5 Smallest: [TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61]), TensorShape([26, 61])]\n",
            "  Average Size: (28.857963875205254, 67.94022988505748)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def analyze_image_sizes(directory_path):\n",
        "    image_sizes = {}\n",
        "    for class_name in os.listdir(directory_path):\n",
        "        class_path = os.path.join(directory_path, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "        sizes = []\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            image = tf.io.read_file(image_path)\n",
        "            image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "            sizes.append(image.shape[:2])  # (height, width)\n",
        "        image_sizes[class_name] = sizes\n",
        "\n",
        "    return image_sizes\n",
        "\n",
        "def summarize_sizes(image_sizes):\n",
        "    all_sizes = []\n",
        "    for class_name, sizes in image_sizes.items():\n",
        "        sizes.sort(key=lambda x: (x[0] * x[1]), reverse=True)  # Sort by area\n",
        "        print(f\"Class '{class_name}':\")\n",
        "        print(f\"  5 Largest: {sizes[:5]}\")\n",
        "        print(f\"  5 Smallest: {sizes[-5:]}\")\n",
        "        avg_height = sum(size[0] for size in sizes) / len(sizes)\n",
        "        avg_width = sum(size[1] for size in sizes) / len(sizes)\n",
        "        print(f\"  Average Size: {(avg_height, avg_width)}\")\n",
        "        all_sizes.extend(sizes)\n",
        "\n",
        "    # Global stats\n",
        "    all_sizes.sort(key=lambda x: (x[0] * x[1]), reverse=True)  # Sort by area\n",
        "    print(\"Overall:\")\n",
        "    print(f\"  5 Largest: {all_sizes[:5]}\")\n",
        "    print(f\"  5 Smallest: {all_sizes[-5:]}\")\n",
        "    avg_height = sum(size[0] for size in all_sizes) / len(all_sizes)\n",
        "    avg_width = sum(size[1] for size in all_sizes) / len(all_sizes)\n",
        "    print(f\"  Average Size: {(avg_height, avg_width)}\")\n",
        "\n",
        "directory_path = '/content/parking_dataset/clf-data'  # Path to your dataset directory\n",
        "image_sizes = analyze_image_sizes(directory_path)\n",
        "summarize_sizes(image_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QWixKU-MdK48"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQRU72yldK7w",
        "outputId": "5e3be6dd-2550-40b8-9833-9bfcfa8f62ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4872 images belonging to 2 classes.\n",
            "Found 1218 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/parking_dataset/clf-data\"\n",
        "train_ds = data_gen.flow_from_directory(\n",
        "    directory=dataset_path,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    target_size=(29,68),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = data_gen.flow_from_directory(\n",
        "    directory=dataset_path,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    target_size=(29, 68),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7Xdpq7VEdK-J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define your model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(29, 68, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Change the final layer to match the number of classes in your dataset\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Rbqid9mJuQAp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZWllyd1dLAl",
        "outputId": "538420db-9792-42e5-ec38-7a6f0c8e456c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "153/153 [==============================] - 15s 89ms/step - loss: 0.1242 - accuracy: 0.9583 - val_loss: 0.1087 - val_accuracy: 0.9688\n",
            "Epoch 2/10\n",
            "153/153 [==============================] - 13s 88ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0708 - val_accuracy: 0.9828\n",
            "Epoch 3/10\n",
            "153/153 [==============================] - 13s 87ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0458 - val_accuracy: 0.9836\n",
            "Epoch 4/10\n",
            "153/153 [==============================] - 14s 89ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0237 - val_accuracy: 0.9901\n",
            "Epoch 5/10\n",
            "153/153 [==============================] - 13s 87ms/step - loss: 4.7421e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9885\n",
            "Epoch 6/10\n",
            "153/153 [==============================] - 13s 87ms/step - loss: 1.2796e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9885\n",
            "Epoch 7/10\n",
            "153/153 [==============================] - 13s 87ms/step - loss: 5.9993e-05 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9901\n",
            "Epoch 8/10\n",
            "153/153 [==============================] - 13s 85ms/step - loss: 9.7566e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9910\n",
            "Epoch 9/10\n",
            "153/153 [==============================] - 13s 87ms/step - loss: 4.2100e-05 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
            "Epoch 10/10\n",
            "153/153 [==============================] - 13s 86ms/step - loss: 3.7434e-05 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9910\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/model/path_to_my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVGP9UfXxPrG",
        "outputId": "c1f3d10b-0739-473d-b296-1efa45871276"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysNmOhn_i1oE",
        "outputId": "542fa1cc-0b3f-42f8-c02f-7f069df0349a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/128.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRGO-rhfikYd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner import HyperModel\n",
        "\n",
        "class MyHyperModel(HyperModel):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
        "                         kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
        "                         activation='relu', input_shape=self.input_shape))\n",
        "        model.add(MaxPooling2D(2, 2))\n",
        "        model.add(Conv2D(filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n",
        "                         kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
        "                         activation='relu'))\n",
        "        model.add(MaxPooling2D(2, 2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(units=hp.Int('dense_units', min_value=64, max_value=512, step=64),\n",
        "                        activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbCmtbChiuOM"
      },
      "outputs": [],
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "input_shape = (29, 68, 3)  # Adjust based on your dataset\n",
        "num_classes = 2  # Adjust based on your dataset\n",
        "\n",
        "hypermodel = MyHyperModel(input_shape=input_shape, num_classes=num_classes)\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='/content/my_dir/hparam_tuning',\n",
        "    project_name='hparam_tuning'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1dQWA99iyoX",
        "outputId": "a76ad6e7-58e1-40c5-dec0-d5114b5d903e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 7 Complete [00h 11m 27s]\n",
            "val_accuracy: 0.9778324961662292\n",
            "\n",
            "Best val_accuracy So Far: 0.9819375872612\n",
            "Total elapsed time: 00h 52m 49s\n",
            "\n",
            "Search: Running Trial #8\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |64                |conv_1_filters\n",
            "5                 |5                 |conv_1_kernel\n",
            "256               |192               |conv_2_filters\n",
            "3                 |3                 |conv_2_kernel\n",
            "192               |192               |dense_units\n",
            "0.4               |0.3               |dropout\n",
            "0.001             |0.001             |learning_rate\n",
            "\n",
            "Epoch 1/10\n",
            "153/153 [==============================] - 54s 344ms/step - loss: 1.6971 - accuracy: 0.9540 - val_loss: 0.1104 - val_accuracy: 0.9770\n",
            "Epoch 2/10\n",
            "153/153 [==============================] - 48s 313ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1665 - val_accuracy: 0.9770\n",
            "Epoch 3/10\n",
            "153/153 [==============================] - 50s 329ms/step - loss: 4.1169e-04 - accuracy: 0.9998 - val_loss: 0.2190 - val_accuracy: 0.9729\n",
            "Epoch 4/10\n",
            "153/153 [==============================] - 52s 340ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.2429 - val_accuracy: 0.9745\n",
            "Epoch 5/10\n",
            "153/153 [==============================] - 48s 311ms/step - loss: 5.8694e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9754\n",
            "Epoch 6/10\n",
            " 66/153 [===========>..................] - ETA: 26s - loss: 1.8883e-05 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(train_ds,\n",
        "             epochs=10,\n",
        "             validation_data=val_ds,\n",
        "             callbacks=[stop_early])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HUCtneQsGN_2jSC7PQaU3siF47A7lhcV",
      "authorship_tag": "ABX9TyMus4MOxHRcgmUVuIvEa1WZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}